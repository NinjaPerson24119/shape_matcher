Shape Matcher
The shape matcher code is contained within the "shape_analysis" folders. It is the successor of the "color_analysis" code as it attempts to be as color invariant as possible, at the cost of requiring a more fine shape analyzing solution. The primary advantage of the shape matcher, over deep learning, is the ability to train a model in only a few minutes, meaning that our computer vision is very adaptive without requiring multiple specific detectors to be written and maintained; we can quickly get detections on new shapes simply by creating a 3D model from which to generate a DB. Too, improvements to one detector will affect all other detectors positively since there is a shared backend.
The shape matcher requires a .sa file to be generated by the shape DB creator for each detector that uses it as a backend. These .sa models should be placed into the "/au_vision/shape_dbs" folder and be referenced within the necessary .yaml file.
The backend is a implemented through a single function that takes a detector input image as well as some meta information about that detector. In this way, detectors using the shape matcher can easily get ROIs, but also can add extra code before or after the utility is called, for example, to cull ROIs that are in coming from water reflections, etc.
Algorithm:
The input image is converted to the CIE LAB color space.
gSLICr is used to segment the input image.
The automatic filter is used to produce a mask with multiple gray levels.
An edge detection kernel is used to convert the mask into a binary image (so that only a single findContour call is needed, since it is a CPU function)
OpenCV is used to find contours in a single call.
Contours are simplified then culled by minimum area, if they are touching the image edge, and if they have less than 3 points.
The shape matcher is run on each real time contour
A single shape DB is made with the real time contour
The rough area difference between the real time contour and every DB contour is taken. This means that the difference between each grid square is taken in order to avoid too many pixel-wise differences. Color differences are also taken since some objects might have similar shapes with different colors.
For every potential shape that does not clip the maximum area difference / color difference thresholds, the pixel-wise area difference is taken between the real time contour and that shape. The real time contour must first be centered on the DB frame buffer and maximized while maintaining aspect ratio (this is pre-calculated for DB contours). Both the real time and DB contours must be rasterized for this step, which presents a large bottleneck. This step is unlikely to cull shapes further based on the maximum area difference threshold. The main reason for this step is to provide more accurate pose information by being more able to select the best match for each real time contour. Ratings for each shape are calculated relative to the maximum area difference threshold, since the maximum theoretical area difference is infinity. That is, if a shape does not clip the threshold, it will have at least ~1%. The calculation is: 1 - [area difference] / [max area difference].
If there are multiple real time contours corresponding to a single DB shape, the best match is taken and the rest are thrown away.
Using the found single shape matches, a list of potential shape groups is culled based on whether there are enough real time contours corresponding to shapes required by each group, based on the minimum rating requirement. Groups for which the same real time contour is associated to multiple required shapes are also culled.
The groups are iterated to find the best rated group. The matcher will only return one group, though its function will return a vector, since vectors can be empty. The group rating is the average of the contained shape ratings. It is not a requirement that all of the group's shapes are found, but the group rating will suffer heavily.
A bounding box is inferred from the existing shapes within the best rated group. A bounding box is made for each shape in the group, using the shape's distance from the DB group's overall bound's top left point, scaled by the shape's dimensions divided by the DB shape's dimensions. Since individual shape scales might vary slightly within a shape group, the average of the bounds inferred from each shape is used as the actual group bound.
The best group is returned with the contained shapes, with mappings to the real time contours as well as the associated DB shapes. The returned group also has 3D pose information, with angles typically relative to the camera.
For a more technical description, take a look at "rfcs/0005-improved-shape-analysis.md" This is the second iteration of the shape matcher.
If shape matcher models (.sa) have been pre-generated, they will be stored on the team google drive: https://drive.google.com/open?id=1b25ZMJHWIixkcjgn22LsdK7p1ahZPo9e
Shape Matcher Settings
Unlike gSLICr, the old automatic filter, and the shape DB creator, the shape matcher is configured on a per detector basis. For this reason, it is necessary to nest all shape matcher parameters within a namespace. This namespace should be named exactly the same as the detector name which is used by the detector handler to call the detector.
The database parameter is the DB name relative to "/au_vision/shape_dbs/".
The minimum contour area is the minimum area a contour must have to be considered for matching.
The contour linearization epsilon is how much to simplify contours (reduce points for performance at the cost of accuracy). Higher is more simple.
The area difference threshold is the maximum area difference a real time contour and a shape in the DB can have and still be considered associated.
The color difference threshold is the maximum color difference (on all channels) that a real time contour and a shape in the DB can have and still be considered associated.
The minimum rating is the minimum rating a group must have in order to be considered a match. This does not refer to the minimum rating of an individual shape in any way.
The auto filter parameters are described in the auto filter section. Note the boolean for turning off the auto filter histogram debug output topic. If this is set to true, a very large amount of processing time will be spent rendering the histogram image. This processing time goes up as the histogram bins goes up.
path_detector: (namespace)
database: new_path.sa (string)
minimum_contour_area: 10000 (int)
contour_linearization_epsilon: 3.0 (double)
area_difference_thresh: 200000 (int)
color_difference_thresh: 1000 (int)
minimum_rating: 0.50 (double)
auto_filter_bins: 100 (unsigned char)
auto_filter_black_margin: 30 (unsigned char)
auto_filter_white_margin: 30 (unsigned char)
auto_filter_histogram: false (boolean)
Debug Image Topics
debug_GraySuperPixels
debug_LineOverlay
debug_AverageColors
debug_InputStageContours
debug_AutoFilterMask
debug_AutoFilterHistogram
debug_BinaryMaskWithHud
debug_Edges
The gray super pixels topic will show gSLICr's native output, which is a mask with multiple grays, where each gray uniquely corresponds to a single superpixel.
The line overlay topic will show gSLICr's native wireframe overlay on the color input image. It is useful for ensuring that gSLICr is correctly outlining objects.
The average colors topic will show each superpixel colored with the average of all pixels within each respective superpixel.
The input stage contours topic will show found contours before they are culled. This is useful for tuning the minimum area threshold.
The auto filter shows a mask with multiple grays, where each gray corresponds to a cluster within the auto filter histogram.
The auto filter histogram topic will be empty if the auto filter histogram topic is not enabled. Otherwise it shows a 2D histogram with the AB components of the CIE LAB color space. Empty histogram squares are indicated with a smaller red square. Filled histogram squares are indicated with a smaller blue square, but their shade will also range from black to white, where white indicates a larger number of pixels.
The binary mask with HUD topic will output an image displaying the contours which make it past the culling function. Red contours indicate that they were clipped (did not pass the area / color difference threshold). Blue contours indicate that they were not clipped, but did not match within a group. Green contours indicate that they were matched within a group. Note that there is only ever one positively matched group, so multiple green contours can be considered associated.
The edges topic will output a binary mask of the auto filter mask's edges. This is the image that is passed to OpenCV's contour finding algorithm.

